!obj:pylearn2.train.Train {
    dataset: &train !obj:higgs.load_data {
        start: 0,
        stop: 4000
    },
    model: !obj:pylearn2.models.mlp.MLP {
#	layers is a list [] that specifies the component layers to run in parallel
        layers: [
                 !obj:pylearn2.models.mlp.Sigmoid {
                     layer_name: 'h0',
                     dim: 50,
#			When sparse_init is specified, each unit gets exactly sparse_init non-zero weights initially.
# 			These weights are drawn from N(0,1), so they are quite large compared to how weights are usually initialized.
                     sparse_init: 15,
                 },
                 !obj:pylearn2.models.mlp.Softmax {
                     layer_name: 'y',
                     n_classes: 2,
#sigo pensando que deberia ser n_classes: 2
                     irange: 0.
                 }
                ],
#	nvis is the number of visible units, nhid the number of hidden units, iscale is the standard deviation of initialized weights
        nvis: 27,
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
        learning_rate: 0.1,
        batch_size: 10,
        monitoring_dataset:
# Dataset or dictionary
            {
                'train' : *train,
                'valid' : !obj:higgs.load_data {
                            start: 4001,
                            stop: 4500
                          },
                'test'  : !obj:higgs.load_data {
                            start: 4501,
                            stop: 5000
                          }
            },
        termination_criterion: !obj:pylearn2.termination_criteria.And {
            criteria: [
# an iterable object. A sequence of callables representing termination criteria, with a return value of True indicating that training should continue.
#                !obj:pylearn2.termination_criteria.MonitorBased {
# A termination criterion that pulls out the specified channel in the modelâ€™s monitor and checks to see if it has decreased by a certain proportion of the lowest value in the last N epochs.
#
#                    channel_name: "valid_y_misclass"
#                },
                !obj:pylearn2.termination_criteria.EpochCounter {
                    max_epochs: 100
                }
            ]
        }
    },
    extensions: [
        !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
# A callback that saves a copy of the model every time it achieves a new minimal value of a monitoring channel. Also stores the best model
# in memory.
#             channel_name: 'valid_y_mse' # used only for LinearGaussianClass
             channel_name: 'valid_y_misclass',
             save_path: "${PYLEARN2_TRAIN_FILE_FULL_STEM}_best.pkl"
        },
    ],
    save_freq: 1
}
